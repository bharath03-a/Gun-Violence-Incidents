{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef37d030-f4b3-4dc6-a57d-f78e136ba93e",
   "metadata": {},
   "source": [
    "### Note on what preprocessing should be done\n",
    "Refer Inference and TO DO in the `01_initial_exploratory_analysis.ipynb` File.\n",
    "1) Date format conversion\n",
    "2) Age Column Cleaning\n",
    "3) Removing unwanted Columns\n",
    "4) Check for cleaning on `state`, `city_or_county` and `address`\n",
    "5) Major cleaning reguired for the fields - `gun_stolen`, `gun_type`, `participant_age`, `participant_age_group`, `participant_gender`, `participant_status` and `participant_type`.\n",
    "6) Clean Text Data - `incident_characterstics` and `notes`\n",
    "7) Change data types too\n",
    "\n",
    "And generate visualizations after cleaning too!\n",
    "\n",
    "Leave encoding out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3e34d129-22b0-4e6e-b448-309f148c32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "d82e1896-2f7b-4ee3-8212-bc9df733a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "bd05d21e-337c-418c-9083-b68e05c41575",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5203860b-d41e-4532-b559-1fca1d9fb829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self created packages\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from scripts.visualizations import Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "b032604c-a94a-4f74-82d8-df3184ab45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, sum, desc, explode, split, year, month, dayofweek, length, initcap, trim, lower, \n",
    "    regexp_extract, regexp_replace, max)\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, IntegerType, StringType,\n",
    "    FloatType, BooleanType, DateType, DoubleType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59411081-b313-40df-aa7b-a25396f6736d",
   "metadata": {},
   "source": [
    "### Setting Spark Session and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "b701572d-508e-43ee-b869-a0c84bd42ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bharaths-air:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11c8795d0>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MIS548 Project PreProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "43379dfd-0bde-4cc6-86ca-c2855ee2a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data schema\n",
    "ip_data_schema = StructType([\n",
    "    StructField(\"incident_id\", IntegerType(), True),\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"city_or_county\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"n_killed\", IntegerType(), True),\n",
    "    StructField(\"n_injured\", IntegerType(), True),\n",
    "    StructField(\"incident_url\", StringType(), True),\n",
    "    StructField(\"source_url\", StringType(), True),\n",
    "    StructField(\"incident_url_fields_missing\", BooleanType(), True),\n",
    "    StructField(\"congressional_district\", IntegerType(), True),\n",
    "    StructField(\"gun_stolen\", StringType(), True),\n",
    "    StructField(\"gun_type\", StringType(), True),\n",
    "    StructField(\"incident_characteristics\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"location_description\", StringType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"n_guns_involved\", IntegerType(), True),\n",
    "    StructField(\"notes\", StringType(), True),\n",
    "    StructField(\"participant_age\", StringType(), True),\n",
    "    StructField(\"participant_age_group\", StringType(), True),\n",
    "    StructField(\"participant_gender\", StringType(), True),\n",
    "    StructField(\"participant_name\", StringType(), True),\n",
    "    StructField(\"participant_relationship\", StringType(), True),\n",
    "    StructField(\"participant_status\", StringType(), True),\n",
    "    StructField(\"participant_type\", StringType(), True),\n",
    "    StructField(\"sources\", StringType(), True),\n",
    "    StructField(\"state_house_district\", IntegerType(), True),\n",
    "    StructField(\"state_senate_district\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "7ce652cb-96ec-4f60-92aa-2c03eae81810",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = spark.read.option(\"header\", \"True\") \\\n",
    "                .option(\"inferSchema\", \"True\") \\\n",
    "                .option(\"quote\", '\"') \\\n",
    "                .option(\"escape\", '\"') \\\n",
    "                .option(\"sep\", \",\") \\\n",
    "                .option(\"ignoreLeadingWhiteSpace\", \"True\") \\\n",
    "                .option(\"ignoreTrailingWhiteSpace\", \"True\") \\\n",
    "                .option(\"multiLine\", \"True\") \\\n",
    "                .option(\"mode\", \"PERMISSIVE\") \\\n",
    "                .csv(\"../data/gun-violence-data_01-2013_03-2018.csv\", schema = ip_data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "a26a0b9f-01ff-4b64-b9d9-0680750823bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the data : 239677\n",
      "Number of columns: 29\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records in the data : {ip_data.count()}\")\n",
    "print(f\"Number of columns: {len(ip_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "e67f20a8-ab10-4eb3-850a-30b1c003e44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- incident_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city_or_county: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- n_killed: integer (nullable = true)\n",
      " |-- n_injured: integer (nullable = true)\n",
      " |-- incident_url: string (nullable = true)\n",
      " |-- source_url: string (nullable = true)\n",
      " |-- incident_url_fields_missing: boolean (nullable = true)\n",
      " |-- congressional_district: integer (nullable = true)\n",
      " |-- gun_stolen: string (nullable = true)\n",
      " |-- gun_type: string (nullable = true)\n",
      " |-- incident_characteristics: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- location_description: string (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- n_guns_involved: integer (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- participant_age: string (nullable = true)\n",
      " |-- participant_age_group: string (nullable = true)\n",
      " |-- participant_gender: string (nullable = true)\n",
      " |-- participant_name: string (nullable = true)\n",
      " |-- participant_relationship: string (nullable = true)\n",
      " |-- participant_status: string (nullable = true)\n",
      " |-- participant_type: string (nullable = true)\n",
      " |-- sources: string (nullable = true)\n",
      " |-- state_house_district: integer (nullable = true)\n",
      " |-- state_senate_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ip_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556adbdc-a747-41bd-ae1e-43e95b8d2b67",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd672c7b-5d13-4746-ac4f-6cb9b773f0f2",
   "metadata": {},
   "source": [
    "#### Duplicate Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "51870f1c-66f4-4867-b143-4afdd2a72dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates_except(df, column_to_exclude=\"\"):\n",
    "    \"\"\"\n",
    "    Check for duplicate rows in a DataFrame, excluding a specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to check for duplicates.\n",
    "    column_to_exclude (str): The column to exclude from the duplicate check.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing the duplicate rows and their counts.\n",
    "    \"\"\"\n",
    "    columns_to_check = [col for col in df.columns if col != column_to_exclude]\n",
    "    \n",
    "    df_duplicates = df.groupBy(columns_to_check).count().filter(\"count > 1\")\n",
    "    \n",
    "    return df_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2fef0637-ee54-4faa-b181-7d2c2fa2cd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1202:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ip_data_dup_chk = check_duplicates_except(ip_data)\n",
    "\n",
    "print(f\"Number of Duplicate Rows: {ip_data_dup_chk.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "d3f00afe-6d99-445a-90f1-8b054e7e0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates if there are any\n",
    "# ip_data = ip_data.dropDuplicates()\n",
    "\n",
    "# print(\"DataFrame after dropping duplicates:\")\n",
    "# ip_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3384e1-3ad2-48d9-9ef3-56101bbf716b",
   "metadata": {},
   "source": [
    "#### Null Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "6f930298-5214-476e-9dc4-638f4025e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_counts(df):\n",
    "    \"\"\"\n",
    "    Get counts and percentages of null values in each column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing column names, null counts, and null percentages.\n",
    "    \"\"\"\n",
    "    total_rows = df.count()\n",
    "    \n",
    "    null_counts = df.select([sum(col(c).isNull().cast('int')).alias(c) for c in df.columns])\n",
    "\n",
    "    narrow_null_counts = null_counts.selectExpr(\n",
    "                                    f\"'{null_counts.columns[0]}' as column_name\",\n",
    "                                    f\"{null_counts.columns[0]} as null_count\",\n",
    "                                    f\"({null_counts.columns[0]} / {total_rows} * 100) as null_percentage\")\n",
    "\n",
    "    for c in null_counts.columns[1:]:\n",
    "        next_col = null_counts.selectExpr(f\"'{c}' as column_name\", \n",
    "                                          f\"{c} as null_count\",\n",
    "                                          f\"({c} / {total_rows} * 100) as null_percentage\")\n",
    "        narrow_null_counts = narrow_null_counts.union(next_col)\n",
    "    \n",
    "    narrow_null_counts = narrow_null_counts.orderBy(desc(\"null_count\"))\n",
    "    \n",
    "    return narrow_null_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1b0c918d-d060-4ba7-a321-2c3b80bc3560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------+-------------------+\n",
      "|column_name                |null_count|null_percentage    |\n",
      "+---------------------------+----------+-------------------+\n",
      "|participant_relationship   |223903    |93.4186425898188   |\n",
      "|location_description       |197588    |82.43928286819344  |\n",
      "|participant_name           |122253    |51.00739745574252  |\n",
      "|gun_stolen                 |99498     |41.51337007722894  |\n",
      "|gun_type                   |99451     |41.493760352474375 |\n",
      "|n_guns_involved            |99451     |41.493760352474375 |\n",
      "|participant_age            |92298     |38.509327136104005 |\n",
      "|notes                      |81017     |33.80257596682201  |\n",
      "|participant_age_group      |42119     |17.573233977394576 |\n",
      "|state_house_district       |38772     |16.17677123795775  |\n",
      "|participant_gender         |36362     |15.171251309053435 |\n",
      "|state_senate_district      |32335     |13.49107340295481  |\n",
      "|participant_status         |27626     |11.526345873821851 |\n",
      "|participant_type           |24863     |10.37354439516516  |\n",
      "|address                    |16497     |6.883013388852498  |\n",
      "|congressional_district     |11944     |4.983373456777246  |\n",
      "|latitude                   |7923      |3.305698919796226  |\n",
      "|longitude                  |7923      |3.305698919796226  |\n",
      "|sources                    |609       |0.25409196543681706|\n",
      "|source_url                 |468       |0.19526279117312048|\n",
      "|incident_characteristics   |326       |0.13601638872315658|\n",
      "|incident_id                |0         |0.0                |\n",
      "|date                       |0         |0.0                |\n",
      "|state                      |0         |0.0                |\n",
      "|city_or_county             |0         |0.0                |\n",
      "|n_killed                   |0         |0.0                |\n",
      "|n_injured                  |0         |0.0                |\n",
      "|incident_url               |0         |0.0                |\n",
      "|incident_url_fields_missing|0         |0.0                |\n",
      "+---------------------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "narrow_null_counts = get_null_counts(ip_data)\n",
    "narrow_null_counts.show(n=29, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0092a-b667-4ed8-a814-49edcfa87e6c",
   "metadata": {},
   "source": [
    "There are some columns which do not add much significance to our analysis. We are dropping those out to aid in the processing  speed.\n",
    "\n",
    "Might drop participant_age_group, state_house_district, state_senate_district, participant_name Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "9140a193-2406-4b8a-8bdf-d29123b3c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_columns = [\"participant_relationship\", \"location_description\", \"sources\", \"source_url\", \n",
    "                   \"incident_url\", \"incident_url_fields_missing\", \"participant_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "6f17b99b-b8f2-4152-81e1-eef9aa07dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.drop(*trivial_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1309c-ee06-4a3b-90e2-bdf34e73f1ae",
   "metadata": {},
   "source": [
    "For missing data, our plan is to impute the data. But some models such as Decision Trees, Random Forest, XGBoost do cater for missing data.\n",
    "\n",
    "My plan is the use different sets of data and verify the performance. Let's see how it goes. So I would do the imputation after all the necessary preprocessing is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd1c44-3d80-48b2-8281-7add9348a017",
   "metadata": {},
   "source": [
    "#### New Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "f345362c-d6f1-4015-a170-7a1f4bba3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.withColumn(\"year\", year(\"date\")) \\\n",
    "                .withColumn(\"month\", month(\"date\")) \\\n",
    "                .withColumn(\"day_of_week\", dayofweek(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "adb6cb2f-9e26-44a1-a7a8-b61f4cd3451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+-----------+\n",
      "|      date|year|month|day_of_week|\n",
      "+----------+----+-----+-----------+\n",
      "|2013-01-01|2013|    1|          3|\n",
      "|2013-01-01|2013|    1|          3|\n",
      "|2013-01-01|2013|    1|          3|\n",
      "|2013-01-05|2013|    1|          7|\n",
      "|2013-01-07|2013|    1|          2|\n",
      "+----------+----+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ip_data.select(\"date\", \"year\", \"month\", \"day_of_week\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fee51c-9066-4fa9-a899-092ac0925274",
   "metadata": {},
   "source": [
    "#### Text Columms\n",
    "\n",
    "First I will focus on the columns such as `state`, `city_or_county` and `address`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ef3103a7-8747-4fae-80a8-6505a2fe7a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abbreviated state entries: 0\n"
     ]
    }
   ],
   "source": [
    "# checking if there are any abbreviated state names in the data\n",
    "\n",
    "abbreviated_states = ip_data.filter(length(\"state\") == 2)\n",
    "abbreviated_count = abbreviated_states.count()\n",
    "print(f\"Number of abbreviated state entries: {abbreviated_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "9cee81e8-95fb-4a99-afcd-6983568f5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_special_characters(ip_data, columns):\n",
    "    \"\"\"\n",
    "    Check for special characters in specified columns and count the occurrences.\n",
    "    \n",
    "    Args:\n",
    "        ip_data (DataFrame): Input DataFrame.\n",
    "        columns (list): List of column names to check for special characters.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with counts of special characters for each specified column.\n",
    "    \"\"\"\n",
    "    special_char_pattern = r\"[^a-zA-Z0-9\\s,'_()-]\"\n",
    "\n",
    "    ip_data_with_special_chars = ip_data.select(\n",
    "        *columns,\n",
    "        *[\n",
    "            (regexp_extract(col_name, special_char_pattern, 0) != \"\").alias(f\"{col_name}_has_special_chars\")\n",
    "            for col_name in columns\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    count_true_values = ip_data_with_special_chars.agg(\n",
    "        *[\n",
    "            sum(col(f\"{col_name}_has_special_chars\").cast(\"int\")).alias(f\"count_{col_name}_special_chars\")\n",
    "            for col_name in columns\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return count_true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3ac8557d-6c04-4973-abe0-6f5df817e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1335:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------------------+---------------------------+\n",
      "|count_state_special_chars|count_city_or_county_special_chars|count_address_special_chars|\n",
      "+-------------------------+----------------------------------+---------------------------+\n",
      "|                        0|                                58|                      15483|\n",
      "+-------------------------+----------------------------------+---------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "columns_to_check = [\"state\", \"city_or_county\", \"address\"]\n",
    "count_result = count_special_characters(ip_data, columns_to_check)\n",
    "\n",
    "count_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "1cbb7b3d-397b-4849-9b67-0d10a8dbeb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entries with 'county' in 'city_or_county': 6331\n"
     ]
    }
   ],
   "source": [
    "# checking county count in the data\n",
    "county_count = ip_data.filter(lower(col(\"city_or_county\")).contains(\"county\")).count()\n",
    "\n",
    "print(f\"Count of entries with 'county' in 'city_or_county': {county_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "eec0cce2-449f-4137-8742-d3a975375518",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.withColumn(\"city_or_county\", trim(col(\"city_or_county\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc031b-2aa9-4d28-962e-267f3c861b47",
   "metadata": {},
   "source": [
    "Finalized transformation related to these columns are:\n",
    "1) `state` : Making sure to trim extra spaces and also capitalizing the first letter of each word.\n",
    "2) `city_or_state` : Making sure to trim extra spaces, replacing the special characters.\n",
    "3) `address` : Making sure to trim extra spaces, replacing the special characters. And mapping `Street` to `St` an other common abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9e9daffb-cd53-45c1-acda-d1aff715d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_type_mapping = {\n",
    "    \"Street\": \"St\",\n",
    "    \"Avenue\": \"Ave\",\n",
    "    \"Road\": \"Rd\",\n",
    "    \"Boulevard\": \"Blvd\",\n",
    "    \"Lane\": \"Ln\",\n",
    "    \"Drive\": \"Dr\",\n",
    "    \"Circle\": \"Cir\",\n",
    "    \"Court\": \"Ct\",\n",
    "    \"Terrace\": \"Ter\",\n",
    "    \"Place\": \"Pl\",\n",
    "    \"Highway\": \"Hwy\",\n",
    "}\n",
    "\n",
    "def replace_street_types(address):\n",
    "    \"\"\"\n",
    "    Replace full street type names in an address with their abbreviations.\n",
    "\n",
    "    Parameters:\n",
    "    address (str): The address string to modify.\n",
    "\n",
    "    Returns:\n",
    "    str: The modified address with street types replaced by abbreviations.\n",
    "    \"\"\"\n",
    "    for full, abbr in street_type_mapping.items():\n",
    "        address = regexp_replace(address, f\"\\\\b{full}\\\\b\", abbr)\n",
    "    return address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "e1a0603d-d9f6-4c17-853e-9b98c859d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data \\\n",
    "    .withColumn(\"state\", initcap(trim(col(\"state\")))) \\\n",
    "    .withColumn(\"city_or_county\", regexp_replace(trim(col(\"city_or_county\")), \"[^a-zA-Z0-9\\s,'_()-]\", \"\")) \\\n",
    "    .withColumn(\"address\", trim(regexp_replace(col(\"address\"), \"[^a-zA-Z0-9\\s,'_()-]\", \"\"))) \\\n",
    "    .withColumn(\"address\", replace_street_types(col(\"address\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee14d63-f82e-4a65-8c2f-750ee7928431",
   "metadata": {},
   "source": [
    "#### Cleaning the wrongly formatted Data\n",
    "\n",
    "Major cleaning reguired for the fields - `gun_stolen`, `gun_type`, `participant_age`, `participant_age_group`, `participant_gender`, `participant_status` and `participant_type`\n",
    "\n",
    "These columns are having data in the form of `0::val1||1::val2`.\n",
    "\n",
    "Need to figure out a way to handle this type of data!\n",
    "\n",
    "First I will get the maximum number of `||` present in these columns to get an idea of how many values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "586616f2-ab54-47c7-82c0-7c77567c6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\n",
    "    \"gun_stolen\", \"gun_type\", \"participant_age\", \"participant_age_group\", \n",
    "    \"participant_gender\", \"participant_status\", \"participant_type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "c1cac540-bf3b-4f31-972f-6ea97416f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_delimiters_count(df, col_name):\n",
    "    \"\"\"\n",
    "    Calculate the maximum count of delimiters (specifically '||') in a specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to analyze.\n",
    "    col_name (str): The name of the column to count delimiters in.\n",
    "\n",
    "    Returns:\n",
    "    int: The maximum count of delimiters found in the specified column.\n",
    "    \"\"\"\n",
    "    delimiter_count_col = (length(col(col_name)) - length(regexp_replace(col(col_name), r\"\\|\\|\", \"\")))\n",
    "    max_count = df.select(delimiter_count_col.alias(f\"{col_name}_delimiter_count\")) \\\n",
    "                  .agg(max(f\"{col_name}_delimiter_count\")).collect()[0][0]\n",
    "    \n",
    "    return max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "ba261fe1-e801-4280-9ee1-fac5a1baa560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in gun_stolen: 798\n",
      "Max number of '||' in gun_type: 798\n",
      "Max number of '||' in participant_age: 130\n",
      "Max number of '||' in participant_age_group: 204\n",
      "Max number of '||' in participant_gender: 154\n",
      "Max number of '||' in participant_status: 204\n",
      "Max number of '||' in participant_type: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in columns_to_check:\n",
    "    max_count = max_delimiters_count(ip_data, col_name)\n",
    "    print(f\"Max number of '||' in {col_name}: {int(max_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "2eadc560-5195-4f31-8b4b-5a8b1ad3c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_delimiters_data(df, col_name):\n",
    "    \"\"\"\n",
    "    Retrieve rows with the maximum count of delimiters (specifically '||') in a specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to analyze.\n",
    "    col_name (str): The name of the column to count delimiters in.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing rows with the maximum delimiter count, including 'incident_id', \n",
    "                the specified column, and the delimiter count.\n",
    "    \"\"\"\n",
    "    max_count = max_delimiters_count(df, col_name)\n",
    "    \n",
    "    result = df.withColumn(f\"{col_name}_delimiter_count\", \n",
    "                           (length(col(col_name)) - length(regexp_replace(col(col_name), r\"\\|\\|\", \"\")))) \\\n",
    "                .filter(col(f\"{col_name}_delimiter_count\") == max_count) \\\n",
    "                .select(\"incident_id\", col_name, f\"{col_name}_delimiter_count\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "f38e47af-f906-454a-a596-063664fc57db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in gun_stolen:\n",
      "+-----------+--------------------+--------------------------+\n",
      "|incident_id|          gun_stolen|gun_stolen_delimiter_count|\n",
      "+-----------+--------------------+--------------------------+\n",
      "|     338106|0::Unknown||1::Un...|                       798|\n",
      "+-----------+--------------------+--------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Incident IDs for max '||' in gun_type:\n",
      "+-----------+--------------------+------------------------+\n",
      "|incident_id|            gun_type|gun_type_delimiter_count|\n",
      "+-----------+--------------------+------------------------+\n",
      "|     338106|0::Unknown||1::Un...|                     798|\n",
      "+-----------+--------------------+------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_age:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------------------+\n",
      "|incident_id|     participant_age|participant_age_delimiter_count|\n",
      "+-----------+--------------------+-------------------------------+\n",
      "|     577157|0::34||1::23||2::...|                            130|\n",
      "+-----------+--------------------+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_age_group:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+-------------------------------------+\n",
      "|incident_id|participant_age_group|participant_age_group_delimiter_count|\n",
      "+-----------+---------------------+-------------------------------------+\n",
      "|     577157| 0::Adult 18+||1::...|                                  204|\n",
      "+-----------+---------------------+-------------------------------------+\n",
      "\n",
      "Incident IDs for max '||' in participant_gender:\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|incident_id|  participant_gender|participant_gender_delimiter_count|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|     577157|0::Male||1::Male|...|                               154|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "\n",
      "Incident IDs for max '||' in participant_status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------------------------------+\n",
      "|incident_id|  participant_status|participant_status_delimiter_count|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|     577157|0::Killed||1::Kil...|                               204|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_type:\n",
      "+-----------+--------------------+--------------------------------+\n",
      "|incident_id|    participant_type|participant_type_delimiter_count|\n",
      "+-----------+--------------------+--------------------------------+\n",
      "|     577157|0::Victim||1::Vic...|                             204|\n",
      "+-----------+--------------------+--------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in columns_to_check:\n",
    "    result_df = max_delimiters_data(ip_data, col_name)\n",
    "    print(f\"Incident IDs for max '||' in {col_name}:\")\n",
    "    result_df.show(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06c68c-179d-4635-a6f3-abd4dbd8ee28",
   "metadata": {},
   "source": [
    "After looking at the `gun_stolen` and `gun_type` are having `Unknown` in their data rather than any meaning full values.\n",
    "As far as rest of the columns go most of them are categorical data so we can creat columns for those and have a count of those values too apart from `participant_age` which we need to figure out a way to store.\n",
    "\n",
    "And the data of `participant_` as prefix are related with theri indexing of the values I guess. So we will get the `n` values only where `n` is the lowest count of any of these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80806d7b-e421-4a52-946a-d4ef151c80aa",
   "metadata": {},
   "source": [
    "##### Handle Unknown Values\n",
    "\n",
    "We can remove these or replace with empty strings for all of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "82aa0f8f-df83-45e7-9f06-d74776c64ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_unknown_values(df, columns):\n",
    "    \"\"\"\n",
    "    Remove 'n::Unknown' patterns from specified columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to clean.\n",
    "    columns (list): List of column names to clean.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The cleaned DataFrame with unknown values removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    unknown_pattern = r\"\\d+::Unknown(\\|\\|\\d+::Unknown)*\"\n",
    "    \n",
    "    for col_name in columns:\n",
    "        df = df.withColumn(col_name,\n",
    "                           regexp_replace(col(col_name), unknown_pattern, \"\"))\n",
    "        \n",
    "        \n",
    "        df = df.withColumn(col_name,\n",
    "                           regexp_replace(col(col_name), r'\\|\\|+', '||'))\n",
    "\n",
    "        df = df.withColumn(col_name,\n",
    "                           trim(regexp_replace(col(col_name), r'^\\|\\||\\|\\|$', '')))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "78b9384f-b96d-40db-8fd3-610f7d0ca1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = clean_unknown_values(ip_data, columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "5921e1a5-675e-475c-9288-4499ceab03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in gun_stolen: 138\n",
      "Max number of '||' in gun_type: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_age: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_age_group: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_gender: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_status: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1408:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_type: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in columns_to_check:\n",
    "    max_count = max_delimiters_count(ip_data, col_name)\n",
    "    print(f\"Max number of '||' in {col_name}: {int(max_count)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
