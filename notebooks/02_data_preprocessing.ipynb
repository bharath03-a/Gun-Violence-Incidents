{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef37d030-f4b3-4dc6-a57d-f78e136ba93e",
   "metadata": {},
   "source": [
    "### Note on what preprocessing should be done\n",
    "Refer Inference and TO DO in the `01_initial_exploratory_analysis.ipynb` File.\n",
    "1) Date format conversion\n",
    "2) Age Column Cleaning\n",
    "3) Removing unwanted Columns\n",
    "4) Check for cleaning on `state`, `city_or_county` and `address`\n",
    "5) Major cleaning reguired for the fields - `gun_stolen`, `gun_type`, `participant_age`, `participant_age_group`, `participant_gender`, `participant_status` and `participant_type`.\n",
    "6) Clean Text Data - `incident_characterstics` and `notes`\n",
    "7) Change data types too\n",
    "\n",
    "And generate visualizations after cleaning too!\n",
    "\n",
    "Leave encoding out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e34d129-22b0-4e6e-b448-309f148c32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82e1896-2f7b-4ee3-8212-bc9df733a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd05d21e-337c-418c-9083-b68e05c41575",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5203860b-d41e-4532-b559-1fca1d9fb829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self created packages\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from scripts.visualizations import Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b032604c-a94a-4f74-82d8-df3184ab45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, sum, desc, explode, split, year, month, dayofweek, length, initcap, trim, lower, \n",
    "    regexp_extract, regexp_replace, max, explode, count, when)\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, IntegerType, StringType,\n",
    "    FloatType, BooleanType, DateType, DoubleType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59411081-b313-40df-aa7b-a25396f6736d",
   "metadata": {},
   "source": [
    "### Setting Spark Session and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b701572d-508e-43ee-b869-a0c84bd42ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/22 00:21:35 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bharaths-air:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1085e62d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MIS548 Project PreProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43379dfd-0bde-4cc6-86ca-c2855ee2a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data schema\n",
    "ip_data_schema = StructType([\n",
    "    StructField(\"incident_id\", IntegerType(), True),\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"city_or_county\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"n_killed\", IntegerType(), True),\n",
    "    StructField(\"n_injured\", IntegerType(), True),\n",
    "    StructField(\"incident_url\", StringType(), True),\n",
    "    StructField(\"source_url\", StringType(), True),\n",
    "    StructField(\"incident_url_fields_missing\", BooleanType(), True),\n",
    "    StructField(\"congressional_district\", IntegerType(), True),\n",
    "    StructField(\"gun_stolen\", StringType(), True),\n",
    "    StructField(\"gun_type\", StringType(), True),\n",
    "    StructField(\"incident_characteristics\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"location_description\", StringType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"n_guns_involved\", IntegerType(), True),\n",
    "    StructField(\"notes\", StringType(), True),\n",
    "    StructField(\"participant_age\", StringType(), True),\n",
    "    StructField(\"participant_age_group\", StringType(), True),\n",
    "    StructField(\"participant_gender\", StringType(), True),\n",
    "    StructField(\"participant_name\", StringType(), True),\n",
    "    StructField(\"participant_relationship\", StringType(), True),\n",
    "    StructField(\"participant_status\", StringType(), True),\n",
    "    StructField(\"participant_type\", StringType(), True),\n",
    "    StructField(\"sources\", StringType(), True),\n",
    "    StructField(\"state_house_district\", IntegerType(), True),\n",
    "    StructField(\"state_senate_district\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce652cb-96ec-4f60-92aa-2c03eae81810",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = spark.read.option(\"header\", \"True\") \\\n",
    "                .option(\"inferSchema\", \"True\") \\\n",
    "                .option(\"quote\", '\"') \\\n",
    "                .option(\"escape\", '\"') \\\n",
    "                .option(\"sep\", \",\") \\\n",
    "                .option(\"ignoreLeadingWhiteSpace\", \"True\") \\\n",
    "                .option(\"ignoreTrailingWhiteSpace\", \"True\") \\\n",
    "                .option(\"multiLine\", \"True\") \\\n",
    "                .option(\"mode\", \"PERMISSIVE\") \\\n",
    "                .csv(\"../data/gun-violence-data_01-2013_03-2018.csv\", schema = ip_data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26a0b9f-01ff-4b64-b9d9-0680750823bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the data : 239677\n",
      "Number of columns: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records in the data : {ip_data.count()}\")\n",
    "print(f\"Number of columns: {len(ip_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67f20a8-ab10-4eb3-850a-30b1c003e44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- incident_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city_or_county: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- n_killed: integer (nullable = true)\n",
      " |-- n_injured: integer (nullable = true)\n",
      " |-- incident_url: string (nullable = true)\n",
      " |-- source_url: string (nullable = true)\n",
      " |-- incident_url_fields_missing: boolean (nullable = true)\n",
      " |-- congressional_district: integer (nullable = true)\n",
      " |-- gun_stolen: string (nullable = true)\n",
      " |-- gun_type: string (nullable = true)\n",
      " |-- incident_characteristics: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- location_description: string (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- n_guns_involved: integer (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- participant_age: string (nullable = true)\n",
      " |-- participant_age_group: string (nullable = true)\n",
      " |-- participant_gender: string (nullable = true)\n",
      " |-- participant_name: string (nullable = true)\n",
      " |-- participant_relationship: string (nullable = true)\n",
      " |-- participant_status: string (nullable = true)\n",
      " |-- participant_type: string (nullable = true)\n",
      " |-- sources: string (nullable = true)\n",
      " |-- state_house_district: integer (nullable = true)\n",
      " |-- state_senate_district: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ip_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556adbdc-a747-41bd-ae1e-43e95b8d2b67",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd672c7b-5d13-4746-ac4f-6cb9b773f0f2",
   "metadata": {},
   "source": [
    "#### Duplicate Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51870f1c-66f4-4867-b143-4afdd2a72dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates_except(df, column_to_exclude=\"\"):\n",
    "    \"\"\"\n",
    "    Check for duplicate rows in a DataFrame, excluding a specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to check for duplicates.\n",
    "    column_to_exclude (str): The column to exclude from the duplicate check.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing the duplicate rows and their counts.\n",
    "    \"\"\"\n",
    "    columns_to_check = [col for col in df.columns if col != column_to_exclude]\n",
    "    \n",
    "    df_duplicates = df.groupBy(columns_to_check).count().filter(\"count > 1\")\n",
    "    \n",
    "    return df_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fef0637-ee54-4faa-b181-7d2c2fa2cd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/22 00:21:38 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ip_data_dup_chk = check_duplicates_except(ip_data)\n",
    "\n",
    "print(f\"Number of Duplicate Rows: {ip_data_dup_chk.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f00afe-6d99-445a-90f1-8b054e7e0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates if there are any\n",
    "# ip_data = ip_data.dropDuplicates()\n",
    "\n",
    "# print(\"DataFrame after dropping duplicates:\")\n",
    "# ip_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3384e1-3ad2-48d9-9ef3-56101bbf716b",
   "metadata": {},
   "source": [
    "#### Null Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f930298-5214-476e-9dc4-638f4025e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_counts(df):\n",
    "    \"\"\"\n",
    "    Get counts and percentages of null values in each column of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing column names, null counts, and null percentages.\n",
    "    \"\"\"\n",
    "    total_rows = df.count()\n",
    "    \n",
    "    null_counts = df.select([sum(col(c).isNull().cast('int')).alias(c) for c in df.columns])\n",
    "\n",
    "    narrow_null_counts = null_counts.selectExpr(\n",
    "                                    f\"'{null_counts.columns[0]}' as column_name\",\n",
    "                                    f\"{null_counts.columns[0]} as null_count\",\n",
    "                                    f\"({null_counts.columns[0]} / {total_rows} * 100) as null_percentage\")\n",
    "\n",
    "    for c in null_counts.columns[1:]:\n",
    "        next_col = null_counts.selectExpr(f\"'{c}' as column_name\", \n",
    "                                          f\"{c} as null_count\",\n",
    "                                          f\"({c} / {total_rows} * 100) as null_percentage\")\n",
    "        narrow_null_counts = narrow_null_counts.union(next_col)\n",
    "    \n",
    "    narrow_null_counts = narrow_null_counts.orderBy(desc(\"null_count\"))\n",
    "    \n",
    "    return narrow_null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b0c918d-d060-4ba7-a321-2c3b80bc3560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------+-------------------+\n",
      "|column_name                |null_count|null_percentage    |\n",
      "+---------------------------+----------+-------------------+\n",
      "|participant_relationship   |223903    |93.4186425898188   |\n",
      "|location_description       |197588    |82.43928286819344  |\n",
      "|participant_name           |122253    |51.00739745574252  |\n",
      "|gun_stolen                 |99498     |41.51337007722894  |\n",
      "|gun_type                   |99451     |41.493760352474375 |\n",
      "|n_guns_involved            |99451     |41.493760352474375 |\n",
      "|participant_age            |92298     |38.509327136104005 |\n",
      "|notes                      |81017     |33.80257596682201  |\n",
      "|participant_age_group      |42119     |17.573233977394576 |\n",
      "|state_house_district       |38772     |16.17677123795775  |\n",
      "|participant_gender         |36362     |15.171251309053435 |\n",
      "|state_senate_district      |32335     |13.49107340295481  |\n",
      "|participant_status         |27626     |11.526345873821851 |\n",
      "|participant_type           |24863     |10.37354439516516  |\n",
      "|address                    |16497     |6.883013388852498  |\n",
      "|congressional_district     |11944     |4.983373456777246  |\n",
      "|latitude                   |7923      |3.305698919796226  |\n",
      "|longitude                  |7923      |3.305698919796226  |\n",
      "|sources                    |609       |0.25409196543681706|\n",
      "|source_url                 |468       |0.19526279117312048|\n",
      "|incident_characteristics   |326       |0.13601638872315658|\n",
      "|incident_id                |0         |0.0                |\n",
      "|date                       |0         |0.0                |\n",
      "|state                      |0         |0.0                |\n",
      "|city_or_county             |0         |0.0                |\n",
      "|n_killed                   |0         |0.0                |\n",
      "|n_injured                  |0         |0.0                |\n",
      "|incident_url               |0         |0.0                |\n",
      "|incident_url_fields_missing|0         |0.0                |\n",
      "+---------------------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "narrow_null_counts = get_null_counts(ip_data)\n",
    "narrow_null_counts.show(n=29, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0092a-b667-4ed8-a814-49edcfa87e6c",
   "metadata": {},
   "source": [
    "There are some columns which do not add much significance to our analysis. We are dropping those out to aid in the processing  speed.\n",
    "\n",
    "Might drop participant_age_group, state_house_district, state_senate_district, participant_name Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9140a193-2406-4b8a-8bdf-d29123b3c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_columns = [\"participant_relationship\", \"location_description\", \"sources\", \"source_url\", \n",
    "                   \"incident_url\", \"incident_url_fields_missing\", \"participant_name\", \"state_house_district\",\n",
    "                   \"state_senate_district\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f17b99b-b8f2-4152-81e1-eef9aa07dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.drop(*trivial_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1309c-ee06-4a3b-90e2-bdf34e73f1ae",
   "metadata": {},
   "source": [
    "For missing data, our plan is to impute the data. But some models such as Decision Trees, Random Forest, XGBoost do cater for missing data.\n",
    "\n",
    "My plan is the use different sets of data and verify the performance. Let's see how it goes. So I would do the imputation after all the necessary preprocessing is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd1c44-3d80-48b2-8281-7add9348a017",
   "metadata": {},
   "source": [
    "#### New Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f345362c-d6f1-4015-a170-7a1f4bba3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.withColumn(\"year\", year(\"date\")) \\\n",
    "                .withColumn(\"month\", month(\"date\")) \\\n",
    "                .withColumn(\"day_of_week\", dayofweek(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adb6cb2f-9e26-44a1-a7a8-b61f4cd3451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+-----------+\n",
      "|      date|year|month|day_of_week|\n",
      "+----------+----+-----+-----------+\n",
      "|2013-01-01|2013|    1|          3|\n",
      "|2013-01-01|2013|    1|          3|\n",
      "|2013-01-01|2013|    1|          3|\n",
      "|2013-01-05|2013|    1|          7|\n",
      "|2013-01-07|2013|    1|          2|\n",
      "+----------+----+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ip_data.select(\"date\", \"year\", \"month\", \"day_of_week\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fee51c-9066-4fa9-a899-092ac0925274",
   "metadata": {},
   "source": [
    "#### Text Columms\n",
    "\n",
    "First I will focus on the columns such as `state`, `city_or_county` and `address`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef3103a7-8747-4fae-80a8-6505a2fe7a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abbreviated state entries: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# checking if there are any abbreviated state names in the data\n",
    "\n",
    "abbreviated_states = ip_data.filter(length(\"state\") == 2)\n",
    "abbreviated_count = abbreviated_states.count()\n",
    "print(f\"Number of abbreviated state entries: {abbreviated_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cee81e8-95fb-4a99-afcd-6983568f5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_special_characters(ip_data, columns):\n",
    "    \"\"\"\n",
    "    Check for special characters in specified columns and count the occurrences.\n",
    "    \n",
    "    Args:\n",
    "        ip_data (DataFrame): Input DataFrame.\n",
    "        columns (list): List of column names to check for special characters.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with counts of special characters for each specified column.\n",
    "    \"\"\"\n",
    "    special_char_pattern = r\"[^a-zA-Z0-9\\s,'_()-]\"\n",
    "\n",
    "    ip_data_with_special_chars = ip_data.select(\n",
    "        *columns,\n",
    "        *[\n",
    "            (regexp_extract(col_name, special_char_pattern, 0) != \"\").alias(f\"{col_name}_has_special_chars\")\n",
    "            for col_name in columns\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    count_true_values = ip_data_with_special_chars.agg(\n",
    "        *[\n",
    "            sum(col(f\"{col_name}_has_special_chars\").cast(\"int\")).alias(f\"count_{col_name}_special_chars\")\n",
    "            for col_name in columns\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return count_true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac8557d-6c04-4973-abe0-6f5df817e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 136:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------------------+---------------------------+\n",
      "|count_state_special_chars|count_city_or_county_special_chars|count_address_special_chars|\n",
      "+-------------------------+----------------------------------+---------------------------+\n",
      "|                        0|                                58|                      15483|\n",
      "+-------------------------+----------------------------------+---------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "columns_to_check = [\"state\", \"city_or_county\", \"address\"]\n",
    "count_result = count_special_characters(ip_data, columns_to_check)\n",
    "\n",
    "count_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cbb7b3d-397b-4849-9b67-0d10a8dbeb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entries with 'county' in 'city_or_county': 6331\n"
     ]
    }
   ],
   "source": [
    "# checking county count in the data\n",
    "county_count = ip_data.filter(lower(col(\"city_or_county\")).contains(\"county\")).count()\n",
    "\n",
    "print(f\"Count of entries with 'county' in 'city_or_county': {county_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eec0cce2-449f-4137-8742-d3a975375518",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data.withColumn(\"city_or_county\", trim(col(\"city_or_county\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc031b-2aa9-4d28-962e-267f3c861b47",
   "metadata": {},
   "source": [
    "Finalized transformation related to these columns are:\n",
    "1) `state` : Making sure to trim extra spaces and also capitalizing the first letter of each word.\n",
    "2) `city_or_state` : Making sure to trim extra spaces, replacing the special characters.\n",
    "3) `address` : Making sure to trim extra spaces, replacing the special characters. And mapping `Street` to `St` an other common abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e9daffb-cd53-45c1-acda-d1aff715d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_type_mapping = {\n",
    "    \"Street\": \"St\",\n",
    "    \"Avenue\": \"Ave\",\n",
    "    \"Road\": \"Rd\",\n",
    "    \"Boulevard\": \"Blvd\",\n",
    "    \"Lane\": \"Ln\",\n",
    "    \"Drive\": \"Dr\",\n",
    "    \"Circle\": \"Cir\",\n",
    "    \"Court\": \"Ct\",\n",
    "    \"Terrace\": \"Ter\",\n",
    "    \"Place\": \"Pl\",\n",
    "    \"Highway\": \"Hwy\",\n",
    "}\n",
    "\n",
    "def replace_street_types(address):\n",
    "    \"\"\"\n",
    "    Replace full street type names in an address with their abbreviations.\n",
    "\n",
    "    Parameters:\n",
    "    address (str): The address string to modify.\n",
    "\n",
    "    Returns:\n",
    "    str: The modified address with street types replaced by abbreviations.\n",
    "    \"\"\"\n",
    "    for full, abbr in street_type_mapping.items():\n",
    "        address = regexp_replace(address, f\"\\\\b{full}\\\\b\", abbr)\n",
    "    return address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1a0603d-d9f6-4c17-853e-9b98c859d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = ip_data \\\n",
    "    .withColumn(\"state\", initcap(trim(col(\"state\")))) \\\n",
    "    .withColumn(\"city_or_county\", regexp_replace(trim(col(\"city_or_county\")), \"[^a-zA-Z0-9\\s,'_()-]\", \"\")) \\\n",
    "    .withColumn(\"address\", trim(regexp_replace(col(\"address\"), \"[^a-zA-Z0-9\\s,'_()-]\", \"\"))) \\\n",
    "    .withColumn(\"address\", replace_street_types(col(\"address\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee14d63-f82e-4a65-8c2f-750ee7928431",
   "metadata": {},
   "source": [
    "#### Cleaning the wrongly formatted Data\n",
    "\n",
    "Major cleaning reguired for the fields - `gun_stolen`, `gun_type`, `participant_age`, `participant_age_group`, `participant_gender`, `participant_status` and `participant_type`\n",
    "\n",
    "These columns are having data in the form of `0::val1||1::val2`.\n",
    "\n",
    "Need to figure out a way to handle this type of data!\n",
    "\n",
    "First I will get the maximum number of `||` present in these columns to get an idea of how many values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "586616f2-ab54-47c7-82c0-7c77567c6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\n",
    "    \"gun_stolen\", \"gun_type\", \"participant_age\", \"participant_age_group\", \n",
    "    \"participant_gender\", \"participant_status\", \"participant_type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1cac540-bf3b-4f31-972f-6ea97416f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_delimiters_count(df, col_name):\n",
    "    \"\"\"\n",
    "    Calculate the maximum count of delimiters (specifically '||') in a specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to analyze.\n",
    "    col_name (str): The name of the column to count delimiters in.\n",
    "\n",
    "    Returns:\n",
    "    int: The maximum count of delimiters found in the specified column.\n",
    "    \"\"\"\n",
    "    delimiter_count_col = (length(col(col_name)) - length(regexp_replace(col(col_name), r\"\\|\\|\", \"\")))\n",
    "    max_count = df.select(delimiter_count_col.alias(f\"{col_name}_delimiter_count\")) \\\n",
    "                  .agg(max(f\"{col_name}_delimiter_count\")).collect()[0][0]\n",
    "    \n",
    "    return max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba261fe1-e801-4280-9ee1-fac5a1baa560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in gun_stolen: 798\n",
      "Max number of '||' in gun_type: 798\n",
      "Max number of '||' in participant_age: 130\n",
      "Max number of '||' in participant_age_group: 204\n",
      "Max number of '||' in participant_gender: 154\n",
      "Max number of '||' in participant_status: 204\n",
      "Max number of '||' in participant_type: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in columns_to_check:\n",
    "    max_count = max_delimiters_count(ip_data, col_name)\n",
    "    print(f\"Max number of '||' in {col_name}: {int(max_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2eadc560-5195-4f31-8b4b-5a8b1ad3c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_delimiters_data(df, col_name):\n",
    "    \"\"\"\n",
    "    Retrieve rows with the maximum count of delimiters (specifically '||') in a specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to analyze.\n",
    "    col_name (str): The name of the column to count delimiters in.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing rows with the maximum delimiter count, including 'incident_id', \n",
    "                the specified column, and the delimiter count.\n",
    "    \"\"\"\n",
    "    max_count = max_delimiters_count(df, col_name)\n",
    "    \n",
    "    result = df.withColumn(f\"{col_name}_delimiter_count\", \n",
    "                           (length(col(col_name)) - length(regexp_replace(col(col_name), r\"\\|\\|\", \"\")))) \\\n",
    "                .filter(col(f\"{col_name}_delimiter_count\") == max_count) \\\n",
    "                .select(\"incident_id\", col_name, f\"{col_name}_delimiter_count\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f38e47af-f906-454a-a596-063664fc57db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in gun_stolen:\n",
      "+-----------+--------------------+--------------------------+\n",
      "|incident_id|          gun_stolen|gun_stolen_delimiter_count|\n",
      "+-----------+--------------------+--------------------------+\n",
      "|     338106|0::Unknown||1::Un...|                       798|\n",
      "+-----------+--------------------+--------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in gun_type:\n",
      "+-----------+--------------------+------------------------+\n",
      "|incident_id|            gun_type|gun_type_delimiter_count|\n",
      "+-----------+--------------------+------------------------+\n",
      "|     338106|0::Unknown||1::Un...|                     798|\n",
      "+-----------+--------------------+------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Incident IDs for max '||' in participant_age:\n",
      "+-----------+--------------------+-------------------------------+\n",
      "|incident_id|     participant_age|participant_age_delimiter_count|\n",
      "+-----------+--------------------+-------------------------------+\n",
      "|     577157|0::34||1::23||2::...|                            130|\n",
      "+-----------+--------------------+-------------------------------+\n",
      "\n",
      "Incident IDs for max '||' in participant_age_group:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+-------------------------------------+\n",
      "|incident_id|participant_age_group|participant_age_group_delimiter_count|\n",
      "+-----------+---------------------+-------------------------------------+\n",
      "|     577157| 0::Adult 18+||1::...|                                  204|\n",
      "+-----------+---------------------+-------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_gender:\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|incident_id|  participant_gender|participant_gender_delimiter_count|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|     577157|0::Male||1::Male|...|                               154|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "\n",
      "Incident IDs for max '||' in participant_status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------------------------------+\n",
      "|incident_id|  participant_status|participant_status_delimiter_count|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|     577157|0::Killed||1::Kil...|                               204|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "\n",
      "Incident IDs for max '||' in participant_type:\n",
      "+-----------+--------------------+--------------------------------+\n",
      "|incident_id|    participant_type|participant_type_delimiter_count|\n",
      "+-----------+--------------------+--------------------------------+\n",
      "|     577157|0::Victim||1::Vic...|                             204|\n",
      "+-----------+--------------------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col_name in columns_to_check:\n",
    "    result_df = max_delimiters_data(ip_data, col_name)\n",
    "    print(f\"Incident IDs for max '||' in {col_name}:\")\n",
    "    result_df.show(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06c68c-179d-4635-a6f3-abd4dbd8ee28",
   "metadata": {},
   "source": [
    "After looking at the `gun_stolen` and `gun_type` are having `Unknown` in their data rather than any meaning full values.\n",
    "As far as rest of the columns go most of them are categorical data so we can creat columns for those and have a count of those values too apart from `participant_age` which we need to figure out a way to store.\n",
    "\n",
    "And the data of `participant_` as prefix are related with theri indexing of the values I guess. So we will get the `n` values only where `n` is the lowest count of any of these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80806d7b-e421-4a52-946a-d4ef151c80aa",
   "metadata": {},
   "source": [
    "##### Handle Unknown Values\n",
    "\n",
    "We can remove these or replace with empty strings for all of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82aa0f8f-df83-45e7-9f06-d74776c64ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_unknown_values(df, columns):\n",
    "    \"\"\"\n",
    "    Clean 'n::Unknown', 'n:Unknown', and mixed patterns from specified columns,\n",
    "    while preserving valid data.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame to clean.\n",
    "    columns (list): List of column names to clean.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The cleaned DataFrame with unknown patterns removed.\n",
    "    \"\"\"\n",
    "    unknown_pattern = r\"(\\d+[:]{1,2}Unknown)(\\|+)?\"\n",
    "\n",
    "    for col_name in columns:\n",
    "        df = df.withColumn(\n",
    "            col_name,\n",
    "            regexp_replace(col(col_name), unknown_pattern, \"\")\n",
    "        )\n",
    "\n",
    "        df = df.withColumn(\n",
    "            col_name,\n",
    "            regexp_replace(col(col_name), r\"\\|\\|+\", \"||\")\n",
    "        )\n",
    "\n",
    "        df = df.withColumn(\n",
    "            col_name,\n",
    "            trim(regexp_replace(col(col_name), r\"^\\|\\||\\|\\|$\", \"\"))\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78b9384f-b96d-40db-8fd3-610f7d0ca1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = clean_unknown_values(ip_data, columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5921e1a5-675e-475c-9288-4499ceab03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in gun_stolen: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in gun_type: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_age: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_age_group: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_gender: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_status: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 209:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of '||' in participant_type: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in columns_to_check:\n",
    "    max_count = max_delimiters_count(ip_data, col_name)\n",
    "    print(f\"Max number of '||' in {col_name}: {int(max_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dca627a8-4d9f-45b3-b4a3-11386ce6d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in gun_stolen:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------------+\n",
      "|incident_id|          gun_stolen|gun_stolen_delimiter_count|\n",
      "+-----------+--------------------+--------------------------+\n",
      "|     366742|0::Stolen||1::Sto...|                       138|\n",
      "+-----------+--------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in gun_type:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------------------+\n",
      "|incident_id|            gun_type|gun_type_delimiter_count|\n",
      "+-----------+--------------------+------------------------+\n",
      "|     623687|0::Handgun||1::Ha...|                     170|\n",
      "+-----------+--------------------+------------------------+\n",
      "\n",
      "Incident IDs for max '||' in participant_age:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------------------+\n",
      "|incident_id|     participant_age|participant_age_delimiter_count|\n",
      "+-----------+--------------------+-------------------------------+\n",
      "|     577157|0::34||1::23||2::...|                            130|\n",
      "+-----------+--------------------+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_age_group:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+-------------------------------------+\n",
      "|incident_id|participant_age_group|participant_age_group_delimiter_count|\n",
      "+-----------+---------------------+-------------------------------------+\n",
      "|     577157| 0::Adult 18+||1::...|                                  204|\n",
      "+-----------+---------------------+-------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_gender:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------------------------------+\n",
      "|incident_id|  participant_gender|participant_gender_delimiter_count|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|     577157|0::Male||1::Male|...|                               154|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------------------------------+\n",
      "|incident_id|  participant_status|participant_status_delimiter_count|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "|     577157|0::Killed||1::Kil...|                               204|\n",
      "+-----------+--------------------+----------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident IDs for max '||' in participant_type:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 239:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------------------+\n",
      "|incident_id|    participant_type|participant_type_delimiter_count|\n",
      "+-----------+--------------------+--------------------------------+\n",
      "|     577157|0::Victim||1::Vic...|                             204|\n",
      "+-----------+--------------------+--------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for col_name in columns_to_check:\n",
    "    result_df = max_delimiters_data(ip_data, col_name)\n",
    "    print(f\"Incident IDs for max '||' in {col_name}:\")\n",
    "    result_df.show(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40c9acbb-02b2-45a1-89b1-8b03b55b797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_encode_cols(df, col_name):\n",
    "    \"\"\"\n",
    "    Cleans and performs one-hot frequency encoding on the specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): Input DataFrame with a delimited column.\n",
    "    col_name (str): Name of the column to clean and encode.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame with one-hot frequency encoded columns.\n",
    "    \"\"\"\n",
    "    pivot_df = ip_data.withColumn(\"value\", explode(split(col(col_name), r\"\\|{1,2}\"))) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"),  r\"(:|::)\", \"\")) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"), r\"\\d+\", \"\")) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"), r\"[\\[\\]{}()]\", \"\")) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"), r\"\\s*[-_.]\\s*\", \" \")) \\\n",
    "                        .withColumn(\"value\", when(col(\"value\") == \"\", \"Unknown\").otherwise(col(\"value\"))) \\\n",
    "                        .withColumn(\"value\", when(col(\"value\") == \"Other\", \"Unknown\").otherwise(col(\"value\"))) \\\n",
    "                        .withColumn(\"value\", lower(trim(col(\"value\")))) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"), r\"\\s+\", \"_\")) \\\n",
    "                        .groupBy(\"incident_id\", \"value\").agg(count(\"value\").alias(\"frequency\")) \\\n",
    "                        .groupBy(\"incident_id\").pivot(\"value\").agg(sum(\"frequency\")).fillna(0)\n",
    "\n",
    "    for pivot_col in pivot_df.columns[1:]:\n",
    "        pivot_df = pivot_df.withColumnRenamed(pivot_col, f\"{col_name}_{pivot_col}_freq\")\n",
    "\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "361011be-66a2-4f8e-a8ce-1832f98a49f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "guns_info = [\"gun_stolen\", \"gun_type\"]\n",
    "\n",
    "final_data = ip_data\n",
    "\n",
    "for col_name in guns_info:\n",
    "    guns_one_hot_df = clean_and_encode_cols(final_data, col_name)\n",
    "    final_data = final_data.join(guns_one_hot_df, on=\"incident_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475db9f-b703-4433-afc5-0417bb291031",
   "metadata": {},
   "source": [
    "For participants data columns we are not going to to for `participant_age` as it has so many values and since we have `participant_age_group` we will use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e381991-5921-4ee4-9c72-1e63144830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_encode_particpant_cols(df, col_name):\n",
    "    \"\"\"\n",
    "    Cleans and performs one-hot frequency encoding on the specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): Input DataFrame with a delimited column.\n",
    "    col_name (str): Name of the column to clean and encode.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame with one-hot frequency encoded columns.\n",
    "    \"\"\"\n",
    "    pivot_df = ip_data.withColumn(\"value\", explode(split(col(col_name), r\"\\|{1,2}\"))) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"),  r\"(:|::)\", \"\")) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"), r\"\\+\", \"plus\")) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"), r\"^\\d+\", \"\")) \\\n",
    "                        .withColumn(\"value\", when(col(\"value\") == \"\", \"Unknown\").otherwise(col(\"value\"))) \\\n",
    "                        .withColumn(\"value\", when(col(\"value\") == \"Other\", \"Unknown\").otherwise(col(\"value\"))) \\\n",
    "                        .withColumn(\"value\", lower(trim(col(\"value\")))) \\\n",
    "                        .withColumn(\"value\", regexp_replace(col(\"value\"), r\"[\\s-]+\", \"_\")) \\\n",
    "                        .groupBy(\"incident_id\", \"value\").agg(count(\"value\").alias(\"frequency\")) \\\n",
    "                        .groupBy(\"incident_id\").pivot(\"value\").agg(sum(\"frequency\")).fillna(0)\n",
    "\n",
    "    for pivot_col in pivot_df.columns[1:]:\n",
    "        pivot_df = pivot_df.withColumnRenamed(pivot_col, f\"{col_name}_{pivot_col}_freq\")\n",
    "\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d68d6ac3-65a1-4324-ae57-1d5cbebb190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_cols = [\"participant_age_group\", \"participant_gender\", \"participant_status\", \"participant_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ad031a2-f2de-42a7-8713-b258c6c7b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleaned_ip_data = final_data\n",
    "\n",
    "for col_name in participant_cols:\n",
    "    participants_one_hot_df = clean_and_encode_particpant_cols(cleaned_ip_data, col_name)\n",
    "    cleaned_ip_data = cleaned_ip_data.join(participants_one_hot_df, on=\"incident_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fddcd80-6f17-4c6f-a102-0342d0c64683",
   "metadata": {},
   "source": [
    "Aggregating `participant_gender_male,_female_freq` to both male and female freq then dropping it, since only one occurance of it is there.\n",
    "\n",
    "And combining and optimizing the `participant_status` columns by aggregating the counts based on the relationships. The goal is to simplify the representation of participant statuses while ensuring that the totals remain accurate.\n",
    "\n",
    "For each main category, aggregate counts from the relevant columns into a single count. For example, if we have columns for `injured,_arrested`, you would add those counts to both `injured_freq` and `arrested_freq`.\n",
    "\n",
    "And then dropping the unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3415e5a5-8415-4dc1-8241-ba29399ab16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ip_data = cleaned_ip_data.withColumn(\"participant_status_arrested_freq\", \n",
    "                                             col(\"participant_status_arrested_freq\") +\n",
    "                                             col(\"participant_status_injured,_arrested_freq\") +\n",
    "                                             col(\"participant_status_killed,_arrested_freq\") +\n",
    "                                             col(\"participant_status_unharmed,_arrested_freq\")) \\\n",
    "                                .withColumn(\"participant_status_injured_freq\", \n",
    "                                            col(\"participant_status_injured_freq\") +\n",
    "                                            col(\"participant_status_injured,_arrested_freq\") +\n",
    "                                            col(\"participant_status_killed,_injured_freq\") +\n",
    "                                            col(\"participant_status_injured,_unharmed_freq\") +\n",
    "                                            col(\"participant_status_injured,_unharmed,_arrested_freq\")) \\\n",
    "                                .withColumn(\"participant_status_killed_freq\", \n",
    "                                            col(\"participant_status_killed_freq\") +\n",
    "                                            col(\"participant_status_killed,_injured_freq\") +\n",
    "                                            col(\"participant_status_killed,_unharmed_freq\") +\n",
    "                                            col(\"participant_status_killed,_arrested_freq\") +\n",
    "                                            col(\"participant_status_killed,_unharmed,_arrested_freq\")) \\\n",
    "                                .withColumn(\"participant_status_unharmed_freq\", \n",
    "                                            col(\"participant_status_unharmed_freq\") +\n",
    "                                            col(\"participant_status_injured,_unharmed_freq\") +\n",
    "                                            col(\"participant_status_killed,_unharmed_freq\") +\n",
    "                                            col(\"participant_status_unharmed,_arrested_freq\") +\n",
    "                                            col(\"participant_status_killed,_unharmed,_arrested_freq\")) \\\n",
    "                                .withColumn(\"participant_gender_female_freq\", \n",
    "                                            col(\"participant_gender_female_freq\") +\n",
    "                                            col(\"participant_gender_male,_female_freq\")) \\\n",
    "                                .withColumn(\"participant_gender_male_freq\", \n",
    "                                            col(\"participant_gender_male_freq\") +\n",
    "                                            col(\"participant_gender_male,_female_freq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6bae458-8a1f-4500-915c-cc7d3209b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"participant_status_injured,_arrested_freq\", \"participant_status_killed,_arrested_freq\",\n",
    "             \"participant_status_unharmed,_arrested_freq\", \"participant_status_killed,_injured_freq\",\n",
    "             \"participant_status_injured,_unharmed_freq\", \"participant_status_injured,_unharmed,_arrested_freq\",\n",
    "             \"participant_status_killed,_unharmed_freq\", \"participant_status_killed,_arrested_freq\",\n",
    "             \"participant_gender_male,_female_freq\", \"participant_age_group\", \"participant_gender\",\n",
    "             \"participant_status\", \"participant_type\", \"participant_status_killed,_unharmed,_arrested_freq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8401ff57-5def-48b4-b7a5-25d1dc153fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ip_data = cleaned_ip_data.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eba30b-0000-4811-bb1e-66c00ded3dde",
   "metadata": {},
   "source": [
    "#### Cleaning Text Columns\n",
    "\n",
    "We have `incident_characteristics` and `notes`\n",
    "\n",
    "Starting with `incident_characteristics` then will implement similar nlp pre-processing tasks on both `incident_characteristics` and `notes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3751cb3-dcd6-4f34-9d95-0689d6825015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt_data(df, column_names):\n",
    "    \"\"\"\n",
    "    Clean the specified column of the DataFrame by replacing certain patterns and normalizing the text.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame.\n",
    "    column_name (str): The name of the column to clean.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The DataFrame with the cleaned column.\n",
    "    \"\"\"\n",
    "    for column_name in column_names:\n",
    "        df = df.withColumn(column_name,\n",
    "                           regexp_replace(col(column_name), r\"\\|{1,2}\", \"; \")) \\\n",
    "               .withColumn(column_name,\n",
    "                           regexp_replace(col(column_name), r\"/\", \" \")) \\\n",
    "               .withColumn(column_name,\n",
    "                           regexp_replace(col(column_name), r\"[^\\w\\s;]\", \"\")) \\\n",
    "               .withColumn(column_name,\n",
    "                           lower(trim(regexp_replace(col(column_name), r\"\\s{2,}\", \" \"))))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b090dfa9-a6cf-445f-8856-39960aa31db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_clean = [\"notes\", \"incident_characteristics\"]\n",
    "cleaned_ip_data = clean_txt_data(cleaned_ip_data, columns_to_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d62e9e1-3c2f-448e-aca3-65d28c9a3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ip_data = cleaned_ip_data.withColumn(\"notes\",\n",
    "                                             regexp_replace(col(\"notes\"), r'[\\d\\s\\.]+$', '')) \\\n",
    "                                .withColumn(\"notes\",\n",
    "                                            regexp_replace(col(\"notes\"), r'\\s*;\\s*$', '')) \\\n",
    "                                .withColumn(\"notes\",\n",
    "                                            regexp_replace(col(\"notes\"), r'\\byr\\b', 'year')) \\\n",
    "                                .withColumn(\"notes\",\n",
    "                                            regexp_replace(col(\"notes\"), r'\\binured\\b', 'injured')) \\\n",
    "                                .withColumn(\"notes\",\n",
    "                                            regexp_replace(col(\"notes\"), r'\\s+', ' ')) \\\n",
    "                                .withColumn(\"notes\", trim(col(\"notes\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96455613-8a4c-4f35-bf26-c11a411d0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- incident_id: integer (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city_or_county: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- n_killed: integer (nullable = true)\n",
      " |-- n_injured: integer (nullable = true)\n",
      " |-- congressional_district: integer (nullable = true)\n",
      " |-- gun_stolen: string (nullable = true)\n",
      " |-- gun_type: string (nullable = true)\n",
      " |-- incident_characteristics: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- n_guns_involved: integer (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- participant_age: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- gun_stolen_not_stolen_freq: long (nullable = true)\n",
      " |-- gun_stolen_stolen_freq: long (nullable = true)\n",
      " |-- gun_stolen_unknown_freq: long (nullable = true)\n",
      " |-- gun_type_ak_freq: long (nullable = true)\n",
      " |-- gun_type_auto_freq: long (nullable = true)\n",
      " |-- gun_type_gauge_freq: long (nullable = true)\n",
      " |-- gun_type_handgun_freq: long (nullable = true)\n",
      " |-- gun_type_lr_freq: long (nullable = true)\n",
      " |-- gun_type_mag_freq: long (nullable = true)\n",
      " |-- gun_type_mm_freq: long (nullable = true)\n",
      " |-- gun_type_rem_ar_freq: long (nullable = true)\n",
      " |-- gun_type_rifle_freq: long (nullable = true)\n",
      " |-- gun_type_shotgun_freq: long (nullable = true)\n",
      " |-- gun_type_spl_freq: long (nullable = true)\n",
      " |-- gun_type_spr_freq: long (nullable = true)\n",
      " |-- gun_type_sw_freq: long (nullable = true)\n",
      " |-- gun_type_unknown_freq: long (nullable = true)\n",
      " |-- gun_type_win_freq: long (nullable = true)\n",
      " |-- participant_age_group_adult_18plus_freq: long (nullable = true)\n",
      " |-- participant_age_group_child_0_11_freq: long (nullable = true)\n",
      " |-- participant_age_group_teen_12_17_freq: long (nullable = true)\n",
      " |-- participant_gender_female_freq: long (nullable = true)\n",
      " |-- participant_gender_male_freq: long (nullable = true)\n",
      " |-- participant_status_arrested_freq: long (nullable = true)\n",
      " |-- participant_status_injured_freq: long (nullable = true)\n",
      " |-- participant_status_killed_freq: long (nullable = true)\n",
      " |-- participant_status_unharmed_freq: long (nullable = true)\n",
      " |-- participant_type_subject_suspect_freq: long (nullable = true)\n",
      " |-- participant_type_victim_freq: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_ip_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b18cee-531d-49f4-a838-7b7b1f2f3f7b",
   "metadata": {},
   "source": [
    "#### Handling `NULL` Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc152246-4c6c-44a0-81fb-3facc8e8e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow_null_counts = get_null_counts(cleaned_ip_data)\n",
    "# narrow_null_counts.show(n=50, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
